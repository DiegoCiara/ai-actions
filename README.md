# ğŸ¤– AI Analytics Service

[![Python](https://img.shields.io/badge/python-3.11+-blue.svg)](https://python.org)
[![FastAPI](https://img.shields.io/badge/FastAPI-0.115.0-009688.svg)](https://fastapi.tiangolo.com)
[![License](https://img.shields.io/badge/license-Internal-red.svg)](LICENSE)

ServiÃ§o de classificaÃ§Ã£o semÃ¢ntica de eventos JSON usando FastAPI e sentence-transformers com machine learning.

## ğŸ¯ VisÃ£o Geral

O AI Analytics Service Ã© uma API REST que utiliza inteligÃªncia artificial para classificar eventos JSON em etapas de processos de negÃ³cio atravÃ©s de anÃ¡lise semÃ¢ntica. O serviÃ§o usa modelos de linguagem natural (NLP) para entender o contexto dos eventos e determinar a etapa mais adequada no fluxo de trabalho.

### ğŸš€ Principais Funcionalidades

- **ğŸ§  ClassificaÃ§Ã£o SemÃ¢ntica**: Usa embeddings neurais para comparar eventos com etapas de processo
- **âš¡ Cache Inteligente**: Sistema de cache em memÃ³ria para otimizar performance de embeddings
- **ğŸŒ API REST Completa**: Interface HTTP documentada com Swagger/OpenAPI
- **ğŸ—£ï¸ Suporte MultilÃ­ngue**: Modelo MiniLM-L12 com suporte nativo ao portuguÃªs e outros idiomas
- **ğŸ“Š Monitoramento**: MÃ©tricas de performance e logs detalhados
- **ğŸ”§ ConfigurÃ¡vel**: VariÃ¡veis de ambiente para ajuste de performance
- **ğŸ“ˆ EscalÃ¡vel**: Suporte a mÃºltiplos workers para alta demanda

## ğŸ› ï¸ Requisitos

- Python 3.11+
- MemÃ³ria: ~1GB (para carregar o modelo)
- CPU: MÃ­nimo 2 cores (recomendado 4+)

## âš¡ InstalaÃ§Ã£o e ExecuÃ§Ã£o RÃ¡pida

### OpÃ§Ã£o 1: Script Automatizado (Recomendado)

```bash
./setup_and_run.sh
```

### OpÃ§Ã£o 2: Manual

```bash
# Criar ambiente virtual
python3.11 -m venv venv
source venv/bin/activate

# Instalar dependÃªncias
pip install -r requirements.txt

# Executar servidor
uvicorn main:app --host 0.0.0.0 --port 8000
```

### OpÃ§Ã£o 3: Docker

```bash
# Construir imagem
docker build -t ai-analytics-service .

# Executar container
docker run -p 8000:8000 ai-analytics-service
```

## ğŸ§ª Testes

```bash
# Executar testes automatizados
./test_api.sh
```

## ğŸ“– DocumentaÃ§Ã£o da API

### ğŸ” Endpoints DisponÃ­veis

| MÃ©todo | Endpoint    | DescriÃ§Ã£o                         |
| ------ | ----------- | --------------------------------- |
| GET    | `/`         | Health check e status da API      |
| POST   | `/classify` | Classificar evento semanticamente |
| GET    | `/metrics`  | MÃ©tricas do sistema e cache       |
| GET    | `/docs`     | DocumentaÃ§Ã£o Swagger interativa   |
| GET    | `/redoc`    | DocumentaÃ§Ã£o ReDoc alternativa    |

### ğŸ©º Health Check

Verifica se a API estÃ¡ funcionando e se o modelo estÃ¡ carregado:

```bash
curl -X GET "http://localhost:8000/" \
  -H "accept: application/json"
```

**Resposta:**

```json
{
  "status": "ok",
  "message": "API de classificaÃ§Ã£o de eventos rodando!",
  "model_loaded": true,
  "cache_size": 15
}
```

### ğŸ“Š MÃ©tricas do Sistema

ObtÃ©m informaÃ§Ãµes sobre performance e configuraÃ§Ã£o:

```bash
curl -X GET "http://localhost:8000/metrics" \
  -H "accept: application/json"
```

### ğŸ¯ ClassificaÃ§Ã£o de Eventos

#### Exemplo BÃ¡sico - E-commerce

```bash
curl -X POST "http://localhost:8000/classify" \
  -H "Content-Type: application/json" \
  -d '{
    "event": {
      "tipo": "pedido",
      "status": "processando",
      "cliente": "JoÃ£o Silva",
      "valor": 299.99
    },
    "etapas": [
      "Recebimento do pedido",
      "Processamento",
      "PreparaÃ§Ã£o para envio",
      "Enviado",
      "Entregue"
    ]
  }'
```

**Resposta:**

```json
{
  "type": "mover",
  "to": "Processamento",
  "original_event": {
    "tipo": "pedido",
    "status": "processando",
    "cliente": "JoÃ£o Silva",
    "valor": 299.99
  },
  "similarity_score": 0.8945,
  "processing_time_ms": 45.23
}
```

#### Exemplo AvanÃ§ado - Analytics Web

```bash
curl -X POST "http://localhost:8000/classify" \
  -H "Content-Type: application/json" \
  -d '{
    "event": {
      "action": "checkout_completed",
      "user_id": "user_12345",
      "session_id": "sess_abcd1234",
      "cart_value": 599.90,
      "payment_method": "credit_card",
      "items_count": 3
    },
    "etapas": [
      "NavegaÃ§Ã£o inicial",
      "VisualizaÃ§Ã£o de produtos",
      "AdiÃ§Ã£o ao carrinho",
      "InÃ­cio do checkout",
      "FinalizaÃ§Ã£o da compra",
      "ConfirmaÃ§Ã£o do pagamento"
    ]
  }'
```

#### Exemplo - GestÃ£o de Leads CRM

```bash
curl -X POST "http://localhost:8000/classify" \
  -H "Content-Type: application/json" \
  -d '{
    "event": {
      "tipo": "interacao",
      "canal": "email",
      "assunto": "Interesse em demonstraÃ§Ã£o do produto",
      "score_lead": 85,
      "empresa": "Tech Solutions Ltd"
    },
    "etapas": [
      "Lead capturado",
      "QualificaÃ§Ã£o inicial",
      "DemonstraÃ§Ã£o agendada",
      "Proposta enviada",
      "NegociaÃ§Ã£o",
      "Fechamento"
    ]
  }'
```

### ğŸ¨ Casos de Uso Comuns

| Setor          | DescriÃ§Ã£o                     | Exemplo de Etapas                                           |
| -------------- | ----------------------------- | ----------------------------------------------------------- |
| **E-commerce** | Classificar jornada de compra | NavegaÃ§Ã£o â†’ Produto â†’ Carrinho â†’ Checkout â†’ Pagamento       |
| **CRM/Vendas** | GestÃ£o de pipeline comercial  | Lead â†’ QualificaÃ§Ã£o â†’ Demo â†’ Proposta â†’ Fechamento          |
| **Suporte**    | Fluxo de atendimento          | Abertura â†’ Triagem â†’ Atendimento â†’ ResoluÃ§Ã£o â†’ Encerramento |
| **Analytics**  | Eventos de usuÃ¡rio            | Entrada â†’ Engajamento â†’ ConversÃ£o â†’ RetenÃ§Ã£o                |
| **LogÃ­stica**  | Rastreamento de pedidos       | Criado â†’ Processando â†’ Enviado â†’ Em trÃ¢nsito â†’ Entregue     |

## ğŸ“Š DocumentaÃ§Ã£o Interativa

Acesse `http://localhost:8000/docs` para a documentaÃ§Ã£o Swagger automÃ¡tica.

## âš™ï¸ ConfiguraÃ§Ã£o e OtimizaÃ§Ã£o

### ğŸ›ï¸ VariÃ¡veis de Ambiente

| VariÃ¡vel                   | PadrÃ£o | DescriÃ§Ã£o                             |
| -------------------------- | ------ | ------------------------------------- |
| `MAX_CACHE_SIZE`           | 1000   | Tamanho mÃ¡ximo do cache de embeddings |
| `MIN_SIMILARITY_THRESHOLD` | 0.1    | Score mÃ­nimo de similaridade aceito   |
| `OMP_NUM_THREADS`          | 4      | Threads para operaÃ§Ãµes de CPU         |
| `TOKENIZERS_PARALLELISM`   | false  | Paralelismo do tokenizer              |

```bash
# ConfiguraÃ§Ã£o para produÃ§Ã£o
export MAX_CACHE_SIZE=5000
export MIN_SIMILARITY_THRESHOLD=0.2
export OMP_NUM_THREADS=8
export TOKENIZERS_PARALLELISM=false
```

### ğŸš€ Modos de ExecuÃ§Ã£o

#### Desenvolvimento (com reload automÃ¡tico)

```bash
uvicorn main:app --host 0.0.0.0 --port 8000 --reload
```

#### ProduÃ§Ã£o (mÃºltiplos workers)

```bash
uvicorn main:app --host 0.0.0.0 --port 8000 --workers 4
```

#### Background (com logs)

```bash
nohup uvicorn main:app --host 0.0.0.0 --port 8000 --workers 2 > server.log 2>&1 &
```

### ğŸ“Š Benchmarks de Performance

| ConfiguraÃ§Ã£o | Requests/seg   | LatÃªncia MÃ©dia | Uso de MemÃ³ria |
| ------------ | -------------- | -------------- | -------------- |
| 1 worker     | ~50-80 req/s   | 50-80ms        | ~1.2GB         |
| 2 workers    | ~100-150 req/s | 30-50ms        | ~2.2GB         |
| 4 workers    | ~200-300 req/s | 20-35ms        | ~4.0GB         |

_Benchmarks realizados em MacBook Air M2 com eventos de 100-200 caracteres_

## ğŸ› SoluÃ§Ã£o de Problemas

### âŒ Problemas Comuns

#### Erro de compatibilidade NumPy

```bash
# Problema: Conflito de versÃµes NumPy 1.x vs 2.x
# SoluÃ§Ã£o:
pip install "numpy<2.0"
pip install --force-reinstall sentence-transformers torch
```

#### Erro de memÃ³ria insuficiente

```bash
# Problema: OOM (Out of Memory) ao carregar modelo
# SoluÃ§Ãµes:
# 1. Reduzir workers
uvicorn main:app --host 0.0.0.0 --port 8000 --workers 1

# 2. Limitar cache
export MAX_CACHE_SIZE=100

# 3. Usar swap (Linux/macOS)
sudo swapon --show  # verificar swap disponÃ­vel
```

#### Modelo nÃ£o carrega/download falha

```bash
# Problema: Erro ao baixar modelo do HuggingFace
# VerificaÃ§Ãµes:
# 1. ConexÃ£o com internet
curl -I https://huggingface.co

# 2. EspaÃ§o em disco (modelo ~500MB)
df -h

# 3. Cache do modelo
rm -rf ~/.cache/huggingface/
```

#### API retorna "Empty reply from server"

```bash
# Problema: Servidor nÃ£o responde
# DiagnÃ³stico:
lsof -i :8000                    # verificar se porta estÃ¡ ocupada
ps aux | grep uvicorn            # verificar processos
tail -f server.log               # verificar logs de erro

# SoluÃ§Ã£o:
pkill -f "uvicorn main:app"      # matar processos antigos
```

#### Performance baixa/timeouts

```bash
# Problema: LatÃªncia alta ou timeouts
# OtimizaÃ§Ãµes:
export OMP_NUM_THREADS=8         # aumentar threads CPU
export MAX_CACHE_SIZE=2000       # aumentar cache
# Usar SSD para cache do modelo
export TRANSFORMERS_CACHE=/path/to/ssd/cache
```

### ğŸ”§ Ferramentas de Debug

#### Verificar status da API

```bash
# Health check bÃ¡sico
curl -v http://localhost:8000/

# MÃ©tricas detalhadas
curl http://localhost:8000/metrics | jq

# Teste de carga simples
for i in {1..10}; do curl -s http://localhost:8000/ > /dev/null && echo "OK $i"; done
```

#### Monitoramento de recursos

```bash
# CPU e memÃ³ria
top -p $(pgrep -f uvicorn)

# Uso de memÃ³ria especÃ­fico
ps -o pid,vsz,rss,comm -p $(pgrep -f uvicorn)

# ConexÃµes de rede
netstat -tlnp | grep :8000
```

### ğŸ“ Suporte

Se os problemas persistirem:

1. **Verifique os logs**: `tail -f server.log`
2. **Documente o erro**: Inclua stacktrace completo
3. **Ambiente**: Python version, OS, recursos disponÃ­veis
4. **ReproduÃ§Ã£o**: Steps para reproduzir o problema

## ğŸ—ï¸ Arquitetura e Estrutura

### ğŸ“ Estrutura do Projeto

```
ai-analytics-service/
â”œâ”€â”€ ğŸ“„ main.py              # AplicaÃ§Ã£o principal FastAPI
â”œâ”€â”€ ğŸ“‹ requirements.txt     # DependÃªncias Python
â”œâ”€â”€ ğŸ³ Dockerfile          # ConfiguraÃ§Ã£o Docker
â”œâ”€â”€ ğŸš€ setup_and_run.sh   # Script de instalaÃ§Ã£o automÃ¡tica
â”œâ”€â”€ ğŸ§ª test_api.sh         # Testes automatizados da API
â”œâ”€â”€ ğŸ .python-version     # VersÃ£o Python especificada (3.11)
â”œâ”€â”€ ğŸ“ .gitignore         # Arquivos ignorados pelo Git
â”œâ”€â”€ ğŸ“š README.md          # Esta documentaÃ§Ã£o
â””â”€â”€ ğŸ“Š server.log         # Logs do servidor (quando executado)
```

### ğŸ¯ Arquitetura da SoluÃ§Ã£o

```mermaid
graph TD
    A[Cliente HTTP] --> B[FastAPI Server]
    B --> C[ValidaÃ§Ã£o Pydantic]
    C --> D[Processamento de Evento]
    D --> E{Cache Hit?}
    E -->|Sim| F[Recuperar Embeddings]
    E -->|NÃ£o| G[Gerar Embeddings]
    G --> H[Salvar no Cache]
    H --> F
    F --> I[CÃ¡lculo de Similaridade]
    I --> J[Tensor Cosine Similarity]
    J --> K[SeleÃ§Ã£o da Melhor Etapa]
    K --> L[Resposta JSON]
    L --> A
```

### ğŸ§  Componentes Principais

| Componente            | Tecnologia                  | FunÃ§Ã£o                                             |
| --------------------- | --------------------------- | -------------------------------------------------- |
| **API Framework**     | FastAPI                     | Interface HTTP, validaÃ§Ã£o, documentaÃ§Ã£o automÃ¡tica |
| **ML Model**          | SentenceTransformers        | GeraÃ§Ã£o de embeddings semÃ¢nticos                   |
| **Similarity Engine** | PyTorch + Cosine Similarity | CÃ¡lculo de similaridade entre vetores              |
| **Cache Layer**       | Python Dict (in-memory)     | Cache de embeddings para performance               |
| **Validation**        | Pydantic                    | ValidaÃ§Ã£o de tipos e dados de entrada              |
| **Logging**           | Python logging              | Monitoramento e debug                              |

### ğŸ”„ Fluxo de ClassificaÃ§Ã£o

1. **RecepÃ§Ã£o**: API recebe evento JSON + lista de etapas
2. **ValidaÃ§Ã£o**: Pydantic valida formato e tipos dos dados
3. **Preprocessamento**: Evento convertido para texto descritivo
4. **Embedding do Evento**: Texto transformado em vetor semÃ¢ntico
5. **Cache Check**: Verifica se embeddings das etapas jÃ¡ existem
6. **Embedding das Etapas**: Gera embeddings para etapas nÃ£o cacheadas
7. **Similaridade**: Calcula cosine similarity entre evento e todas etapas
8. **SeleÃ§Ã£o**: Escolhe etapa com maior score de similaridade
9. **Resposta**: Retorna resultado com mÃ©tricas de performance

## ğŸ“ˆ Monitoramento

- **Logs**: Uvicorn fornece logs detalhados
- **MÃ©tricas**: Tempo de processamento incluÃ­do na resposta
- **Health**: Endpoint `/` para verificaÃ§Ã£o de saÃºde

## ï¿½ Deploy e ProduÃ§Ã£o

### ğŸ³ Docker Deployment

```bash
# Build da imagem
docker build -t ai-analytics-service:latest .

# ExecuÃ§Ã£o local
docker run -d \
  --name ai-analytics \
  -p 8000:8000 \
  -e MAX_CACHE_SIZE=2000 \
  -e OMP_NUM_THREADS=4 \
  ai-analytics-service:latest

# Com docker-compose
cat > docker-compose.yml << EOF
version: '3.8'
services:
  ai-analytics:
    build: .
    ports:
      - "8000:8000"
    environment:
      - MAX_CACHE_SIZE=2000
      - MIN_SIMILARITY_THRESHOLD=0.15
      - OMP_NUM_THREADS=4
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/"]
      interval: 30s
      timeout: 10s
      retries: 3
EOF

docker-compose up -d
```

### â˜ï¸ Cloud Deployment

#### AWS ECS/Fargate

```bash
# Criar task definition
aws ecs register-task-definition \
  --family ai-analytics-service \
  --requires-compatibilities FARGATE \
  --network-mode awsvpc \
  --cpu 2048 \
  --memory 4096
```

#### Google Cloud Run

```bash
# Deploy direto do cÃ³digo
gcloud run deploy ai-analytics-service \
  --source . \
  --platform managed \
  --region us-central1 \
  --memory 4Gi \
  --cpu 2
```

#### Azure Container Instances

```bash
az container create \
  --resource-group myResourceGroup \
  --name ai-analytics-service \
  --image ai-analytics-service:latest \
  --cpu 2 \
  --memory 4 \
  --ports 8000
```

### âš–ï¸ Load Balancer Configuration

#### Nginx

```nginx
upstream ai_analytics {
    server localhost:8001;
    server localhost:8002;
    server localhost:8003;
}

server {
    listen 80;
    server_name ai-analytics.company.com;

    location / {
        proxy_pass http://ai_analytics;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_connect_timeout 30s;
        proxy_send_timeout 30s;
        proxy_read_timeout 30s;
    }

    location /health {
        access_log off;
        proxy_pass http://ai_analytics/;
    }
}
```

## ï¿½ğŸ”’ SeguranÃ§a e Melhores PrÃ¡ticas

### ğŸ›¡ï¸ SeguranÃ§a para ProduÃ§Ã£o

```python
# Adicionar ao main.py para produÃ§Ã£o
from fastapi.middleware.cors import CORSMiddleware
from fastapi.middleware.trustedhost import TrustedHostMiddleware
import uvicorn

# CORS Configuration
app.add_middleware(
    CORSMiddleware,
    allow_origins=["https://yourdomain.com"],
    allow_credentials=True,
    allow_methods=["GET", "POST"],
    allow_headers=["*"],
)

# Trusted Hosts
app.add_middleware(
    TrustedHostMiddleware,
    allowed_hosts=["yourdomain.com", "*.yourdomain.com"]
)

# Rate Limiting (usando slowapi)
from slowapi import Limiter, _rate_limit_exceeded_handler
from slowapi.util import get_remote_address
from slowapi.errors import RateLimitExceeded

limiter = Limiter(key_func=get_remote_address)
app.state.limiter = limiter
app.add_exception_handler(RateLimitExceeded, _rate_limit_exceeded_handler)

@app.post("/classify")
@limiter.limit("10/minute")  # 10 requests por minuto
async def classify_event(request: Request, data: EventInput):
    # ... resto do cÃ³digo
```

### ğŸ” Checklist de SeguranÃ§a

- [ ] **HTTPS**: Sempre usar SSL/TLS em produÃ§Ã£o
- [ ] **CORS**: Configurar origins permitidos
- [ ] **Rate Limiting**: Implementar limites de requisiÃ§Ã£o
- [ ] **Input Validation**: Validar todos os dados de entrada
- [ ] **API Keys**: Implementar autenticaÃ§Ã£o se necessÃ¡rio
- [ ] **Logs**: NÃ£o logar dados sensÃ­veis
- [ ] **Updates**: Manter dependÃªncias atualizadas
- [ ] **Monitoring**: Configurar alertas de seguranÃ§a

## ğŸ¤ ContribuiÃ§Ã£o e Desenvolvimento

### ğŸ”„ Workflow de Desenvolvimento

```bash
# 1. Clone e setup
git clone https://github.com/DiegoCiara/ai-analytics-service.git
cd ai-analytics-service
./setup_and_run.sh

# 2. Criar branch para feature
git checkout -b feature/nova-funcionalidade

# 3. Desenvolvimento
# ... fazer modificaÃ§Ãµes

# 4. Testes
./test_api.sh
python -m pytest tests/  # se houver testes unitÃ¡rios

# 5. Commit e Push
git add .
git commit -m "feat: adicionar nova funcionalidade"
git push origin feature/nova-funcionalidade

# 6. Pull Request
# Abrir PR no GitHub com descriÃ§Ã£o detalhada
```

### ğŸ“‹ PadrÃµes de CÃ³digo

- **Estilo**: Seguir PEP 8
- **Type Hints**: Usar anotaÃ§Ãµes de tipo
- **Docstrings**: Documentar todas as funÃ§Ãµes
- **Logs**: Usar logging apropriado
- **Testes**: Escrever testes para novas funcionalidades

### ğŸ§ª Executar Testes

```bash
# Testes da API
./test_api.sh

# Testes unitÃ¡rios (se implementados)
python -m pytest tests/ -v

# Coverage
python -m pytest --cov=main tests/

# Linting
flake8 main.py
black main.py --check
```

## ğŸ“Š Roadmap e Futuras Melhorias

### ğŸ¯ PrÃ³ximas VersÃµes

- [ ] **v1.1**: Suporte a mÃºltiplos modelos de embedding
- [ ] **v1.2**: PersistÃªncia de cache em Redis
- [ ] **v1.3**: MÃ©tricas avanÃ§adas com Prometheus
- [ ] **v1.4**: AutenticaÃ§Ã£o JWT
- [ ] **v1.5**: Batch processing para mÃºltiplos eventos
- [ ] **v2.0**: Fine-tuning de modelos personalizados

### ğŸ’¡ Ideias para ContribuiÃ§Ã£o

- Implementar testes unitÃ¡rios abrangentes
- Adicionar suporte a outros modelos (BERT, RoBERTa)
- Criar dashboard web para monitoramento
- Implementar cache distribuÃ­do (Redis/Memcached)
- Adicionar suporte a webhooks para notificaÃ§Ãµes
- Criar SDK/cliente Python para facilitar integraÃ§Ã£o

## ğŸ“„ LicenÃ§a

**Projeto Interno - Todos os direitos reservados**

Este Ã© um projeto interno da empresa. O uso, modificaÃ§Ã£o e distribuiÃ§Ã£o sÃ£o restritos aos membros autorizados da organizaÃ§Ã£o.

---

**ğŸ“ Suporte**: Para questÃµes tÃ©cnicas, abra uma issue no repositÃ³rio ou entre em contato com a equipe de desenvolvimento.

**ğŸ”— Links Ãšteis**:

- [FastAPI Documentation](https://fastapi.tiangolo.com/)
- [Sentence Transformers](https://www.sbert.net/)
- [HuggingFace Models](https://huggingface.co/models)
